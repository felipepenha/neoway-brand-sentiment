{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example string to do mini tests on\n",
    "example = \"I just EASILY had the BEST lunch I've ever eaten!  It was THAT good!\\n\\nThe chicken tortilla soup was out of this world...light and delicate...fresh and HOT!!!\\nI had two fish tacos with no tortilla.  One was a regular fish taco and the other was a beer battered fish taco.l\\n\\nThe fire roasted salsa was EASILY the best salsa I have ever had, too!\\n\\nThis place is a serious gem!  I could go there every single day!\\n\\nThanks guys!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Benepar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package benepar_en2 to\n",
      "[nltk_data]     /Users/TimGimi/nltk_data...\n",
      "[nltk_data]   Package benepar_en2 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import benepar\n",
    "benepar.download(\"benepar_en2\")\n",
    "parser = benepar.Parser(\"benepar_en2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import StanfordNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to first instantiate stanfordNLP in java!\n",
    "\n",
    "java command: \n",
    "\n",
    "``\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -sentiment.threads 8 -port 9000 -timeout 30000``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse: (ROOT\n",
      "  (S\n",
      "    (NP (DT A) (NN blog))\n",
      "    (VP (NN post)\n",
      "      (S\n",
      "        (VP (VBG using)\n",
      "          (NP (NNP Stanford) (NNP CoreNLP) (NN Server)))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import logging\n",
    "import json\n",
    "\n",
    "class StanfordNLP:\n",
    "    def __init__(self, host='http://localhost', port=9000):\n",
    "        self.nlp = StanfordCoreNLP(host, port=port,\n",
    "                                   timeout=30000)  # , quiet=False, logging_level=logging.DEBUG)\n",
    "        self.props = {\n",
    "            'annotators': 'tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref,relation',\n",
    "            'pipelineLanguage': 'en',\n",
    "            'outputFormat': 'json'\n",
    "        }\n",
    "\n",
    "    def word_tokenize(self, sentence):\n",
    "        return self.nlp.word_tokenize(sentence)\n",
    "\n",
    "    def pos(self, sentence):\n",
    "        return self.nlp.pos_tag(sentence)\n",
    "\n",
    "    def ner(self, sentence):\n",
    "        return self.nlp.ner(sentence)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        return self.nlp.parse(sentence)\n",
    "\n",
    "    def dependency_parse(self, sentence):\n",
    "        return self.nlp.dependency_parse(sentence)\n",
    "\n",
    "    def annotate(self, sentence):\n",
    "        return json.loads(self.nlp.annotate(sentence, properties=self.props))\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens_to_dict(_tokens):\n",
    "        tokens = defaultdict(dict)\n",
    "        for token in _tokens:\n",
    "            tokens[int(token['index'])] = {\n",
    "                'word': token['word'],\n",
    "                'lemma': token['lemma'],\n",
    "                'pos': token['pos'],\n",
    "                'ner': token['ner']\n",
    "            }\n",
    "        return tokens\n",
    "\n",
    "    \n",
    "\n",
    "sNLP = StanfordNLP()\n",
    "text = 'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\n",
    "print(\"Parse:\", sNLP.parse(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Entity Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "model_dir = \"./models\"\n",
    "nlp = spacy.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(nlp_model, text):\n",
    "    \"\"\"\n",
    "    Input nlp_model and text, retrieve a list of unique entities from the text.\n",
    "    \"\"\"\n",
    "    doc = nlp_model(text)\n",
    "    entities = set()\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PRODUCT\":\n",
    "            entities.add(ent.text)\n",
    "    return list(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chicken',\n",
       " 'fish',\n",
       " 'lunch',\n",
       " 'tortilla',\n",
       " 'taco',\n",
       " 'gem',\n",
       " 'place',\n",
       " 'salsa',\n",
       " 'beer',\n",
       " 'soup']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entity_list = get_entities(nlp, example)\n",
    "example_entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick fix\n",
    "#example_entity_list = ['chicken tortilla soup', 'fish tacos', 'tortilla', 'beer battered fish taco', 'fire roasted salasa', 'place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I just EASILY had the BEST lunch I've ever eaten!  It was THAT good!\\n\\nThe chicken tortilla soup was out of this world...light and delicate...fresh and HOT!!!\\nI had two fish tacos with no tortilla.  One was a regular fish taco and the other was a beer battered fish taco.l\\n\\nThe fire roasted salsa was EASILY the best salsa I have ever had, too!\\n\\nThis place is a serious gem!  I could go there every single day!\\n\\nThanks guys!!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "def remove_nestings(lst): \n",
    "    output = []\n",
    "    \n",
    "    def remove_nestings_recursive(l):\n",
    "        for i in l: \n",
    "            if type(i) == list: \n",
    "                remove_nestings_recursive(i) \n",
    "            else: \n",
    "                output.append(i)\n",
    "    \n",
    "    remove_nestings_recursive(lst)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def continue_splitting(review,list_of_dividers):\n",
    "        \n",
    "    temp = list_of_dividers.copy()\n",
    "    l = [review]\n",
    "    while len(temp) > 0:\n",
    "        divider = temp.pop(0)\n",
    "        l_new = []\n",
    "        for i in l:\n",
    "            l_new += i.split(divider)\n",
    "        l = l_new\n",
    "    return l\n",
    "\n",
    "def join_clause(review, list_of_split_clauses, list_of_dividers):\n",
    "    output = []\n",
    "    loc_of_split_clauses = []\n",
    "    for clause in list_of_split_clauses:\n",
    "        loc_of_split_clauses.append(review.find(clause))\n",
    "    for divider in list_of_dividers:\n",
    "        print(divider)\n",
    "        loc_div = review.find(divider)\n",
    "        print(loc_div)\n",
    "        for i in range(len(loc_of_split_clauses)):\n",
    "            if loc_div > loc_of_split_clauses[i]:\n",
    "                print(loc_div,loc_of_split_clauses[i])\n",
    "                \n",
    "def join_partitions(long_review,entity_with_review):\n",
    "    loclist = []\n",
    "    for (_, clause) in entity_with_review:\n",
    "        loclist.append((long_review.find(clause),long_review.find(clause)+len(clause)))\n",
    "    starts = {i for (i,j) in loclist}\n",
    "    ends = {j for (i,j) in loclist}\n",
    "    starts.add(len(long_review))\n",
    "    newends = {}\n",
    "    for i in ends:\n",
    "        newends[i] = min([x for x in starts if x >= i])\n",
    "    for i in newends:\n",
    "        pass\n",
    "    new_entity_with_review = []\n",
    "    for i in range(len(loclist)):\n",
    "        tup = loclist[i]\n",
    "        entity = entity_with_review[i][0]\n",
    "        st = tup[0]\n",
    "        en = newends[tup[1]]\n",
    "        new_entity_with_review.append((entity,long_review[st:en]))\n",
    "    return new_entity_with_review\n",
    "\n",
    "def split_long_string(review):\n",
    "    num = len(review)\n",
    "    split_list = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    while num != end:\n",
    "        if num - end < 1000:\n",
    "            end = num\n",
    "            split_list.append(review[start:end])\n",
    "        else:\n",
    "            end = review[start:(start+1000)].rfind('.')\n",
    "            if end == -1:\n",
    "                end = review[start:(start+1000)].rfind(' ') #if no '.', space will do\n",
    "                if end == -1:\n",
    "                    end = min(start + 1000,num)\n",
    "            split_list.append(review[start:end])\n",
    "            start = end\n",
    "    print(start,end)\n",
    "    return(split_list)\n",
    "\n",
    "def split_review_naive(review,entities):\n",
    "    clauses = re.split('[.?!]',review)\n",
    "    lenlist = [len(x) for x in clauses]\n",
    "    clauses = [x for _, x in sorted(zip(lenlist,clauses),reverse=False)]\n",
    "    entity_with_clause = []\n",
    "    for entity in entities:\n",
    "        for clause in clauses:\n",
    "            if entity in clause:\n",
    "                entity_with_clause.append((entity,clause))\n",
    "                break\n",
    "    return(join_partitions(review,entity_with_clause))\n",
    "\n",
    "def min_tree(review, entitiess, parser, output = 'minimum'):\n",
    "    \n",
    "    #review is string, entities is list of strings, parser is parser object\n",
    "    # TODO: How well are each review punctuatd and so forth EDA\n",
    "    if output == 'partition':\n",
    "        full_review = ''\n",
    "        \n",
    "    treelist = []\n",
    "    lenlist = []\n",
    "    temp = review.split('\\n')\n",
    "    \n",
    "    if output == 'no_parse':\n",
    "        return(split_review_naive(review,entities))\n",
    "    \n",
    "    if len(review) > 1000:\n",
    "        split_reviews = split_long_string(review)\n",
    "    else:\n",
    "        split_reviews = [i for i in temp if len(i) > 1 and len(i) <= 1000 ]\n",
    "    \n",
    "    for rev in split_reviews:\n",
    "        if rev and rev.strip():\n",
    "            u = parser.parse(rev) # tree \n",
    "\n",
    "            if type(u) == str:\n",
    "                u = nltk.Tree.fromstring(u)\n",
    "\n",
    "            for s in u.subtrees(): # subtrees \n",
    "                if s.label() == 'S': # if sentence\n",
    "                    treelist += [s]\n",
    "                    lenlist += [len(s.leaves())] # how long clause\n",
    "                        \n",
    "            if output == 'partition':\n",
    "                full_review += ' '.join(u.leaves())\n",
    "\n",
    "    treelist = [x for _, x in sorted(zip(lenlist,treelist),reverse=False)] # sort by lenlisit\n",
    "    clauses = [' '.join(tree.leaves()) for tree in treelist]\n",
    "    if not clauses:\n",
    "        clauses.append(review)\n",
    "    entity_with_clause = []\n",
    "    \n",
    "    if output == 'all':\n",
    "        for entity in entities:\n",
    "            clauselist = []\n",
    "            for clause in clauses:\n",
    "                if entity in clause:\n",
    "                    clauselist.append(clause)\n",
    "            entity_with_clause.append((entity,clauselist))\n",
    "    \n",
    "    #TODO: create rules and test them\n",
    "    elif output == 'minimum':\n",
    "        for entity in entities:\n",
    "            for clause in clauses:\n",
    "                if entity in clause:\n",
    "                    entity_with_clause.append((entity,clause))\n",
    "                    break\n",
    "                    \n",
    "    elif output == 'partition':\n",
    "        #first find minimal clause\n",
    "        for entity in entities:\n",
    "            for clause in clauses:\n",
    "                if entity in clause:\n",
    "                    entity_with_clause.append((entity,clause))\n",
    "                    break\n",
    "        #get location of minimal clause in review\n",
    "        \n",
    "        \n",
    "        entity_with_clause = join_partitions(full_review,entity_with_clause)\n",
    "    \n",
    "    return entity_with_clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANFORD NLP\n",
    "import numpy as np\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "def stanford_sentiment_start():\n",
    "    nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "    return nlp\n",
    "\n",
    "def stanford_sentiment(entity_with_clause):\n",
    "    nlp = stanford_sentiment_start()\n",
    "    entity_with_sentiment = []\n",
    "    for entity, clause in entity_with_clause:\n",
    "        result = nlp.annotate(clause,\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json'\n",
    "                   })\n",
    "        sentiment = np.dot(result['sentences'][0]['sentimentDistribution'], [-2, -1, 0, 1, 2])\n",
    "        entity_with_sentiment.append((entity, sentiment))\n",
    "    return entity_with_sentiment\n",
    "\n",
    "#VADER\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def vader_sentiment(entity_with_clause):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    entity_with_sentiment = []\n",
    "    for entity, clause in entity_with_clause:\n",
    "        sentiment = analyzer.polarity_scores(clause)['compound']\n",
    "        entity_with_sentiment.append((entity,sentiment))\n",
    "    return(entity_with_sentiment)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Werk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def werk(review, entities, parser = [], sentiment_package = 'vader', parse_package = 'benepar', rule = 'rule_1'):\n",
    "    \n",
    "    #print(\"\\nLoading Parser\")\n",
    "    \n",
    "    #first is the parser\n",
    "    if not parser and parse_package == 'benepar':\n",
    "        parser = benepar.Parser(\"benepar_en2\")\n",
    "    elif not parser and parse_package == 'stanford':\n",
    "        #parser = StanfordNLP('http://localhost')\n",
    "        raise Exception('incorrect parse package')\n",
    "    elif parser:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('incorrect parse package')\n",
    "    \n",
    "    #print(\"Parser =\", parse_package)\n",
    "\n",
    "        \n",
    "    #second is the rule\n",
    "    \n",
    "    #print(\"\\nLoading Rule\")\n",
    "    \n",
    "    if rule == 'rule_1':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'minimum')\n",
    "        \n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        \n",
    "        #print(\"\\nSentiment Generated\")\n",
    "\n",
    "        \n",
    "    elif rule == 'rule_2':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'all')\n",
    "        \n",
    "        #print(\"\\nTree Generated\")\n",
    "        entity_with_sentiment = []\n",
    "        sentiment = 0\n",
    "        for ent, revlist in entity_with_review:\n",
    "            for clause in revlist:\n",
    "                sentiment = sentiment_analysis_indiv(clause,sentiment_package)\n",
    "                if sentiment_package == 'benepar' and abs(sentiment) != 0:\n",
    "                    break\n",
    "                elif sentiment_package == 'stanford' and abs(sentiment) > 0.5:\n",
    "                    break\n",
    "                    #if sentiment is not neutral, stop. If sentiment is neutral, keep going up tree.\n",
    "            entity_with_sentiment.append((ent,sentiment))\n",
    "        #print(\"\\nSentiment Generated\")        \n",
    "        \n",
    "    elif rule == 'rule_3':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'all')\n",
    "        \n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = []\n",
    "        for ent, revlist in entity_with_review:\n",
    "            sentiment_list = []\n",
    "            for clause in revlist:\n",
    "                sentiment = sentiment_analysis_indiv(clause,sentiment_package)\n",
    "                sentiment_list.append(sentiment)\n",
    "            if not sentiment_list:\n",
    "                sentiment_list.append(0)\n",
    "            entity_with_sentiment.append((ent,np.mean(sentiment_list)))\n",
    "            \n",
    "        #print(\"\\nSentiment Generated\") \n",
    "        \n",
    "    elif rule == 'rule_4':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'partition')\n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        \n",
    "        #print(\"\\nSentiment Generated\")\n",
    "        \n",
    "    elif rule == 'rule_5':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'minimum')\n",
    "        entity_with_review_p = min_tree(review, entities, parser, output = 'partition')\n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        for i in range(len(entity_with_sentiment)):\n",
    "            sent = entity_with_sentiment[i][1]\n",
    "            if sentiment_package == 'vader' and sent != 0:\n",
    "                entity_with_sentiment[i] = (entity_with_sentiment[i][0],sentiment_analysis_indiv(entity_with_review_p[i][1],sentiment_package))\n",
    "            elif sentiment_package == 'stanford' and abs(sent) > 0.5:\n",
    "                entity_with_sentiment[i] = (entity_with_sentiment[i][0],sentiment_analysis_indiv(entity_with_review_p[i][1],sentiment_package))\n",
    "    \n",
    "    elif rule == 'rule_6':\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'no_parse')\n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        \n",
    "        #print(\"\\nSentiment Generated\")\n",
    "    \n",
    "    else:\n",
    "        raise Exception('incorrect rule')\n",
    "    \n",
    "    return(entity_with_sentiment)\n",
    "    \n",
    "def sentiment_analysis(entity_with_review, sentiment_package = 'stanford'):\n",
    "    #takes in list of tuples\n",
    "    if sentiment_package == 'stanford':\n",
    "        return stanford_sentiment(entity_with_review)\n",
    "    elif sentiment_package == 'vader':\n",
    "        return vader_sentiment(entity_with_review)\n",
    "    else:\n",
    "        raise Exception('incorrect sentiment package')\n",
    "\n",
    "def sentiment_analysis_indiv(clause,sentiment_package = 'stanford'):\n",
    "    #takes in a single review\n",
    "    if sentiment_package == 'stanford':\n",
    "        nlp = stanford_sentiment_start()\n",
    "        result = nlp.annotate(clause,\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json'\n",
    "                   })\n",
    "        print(result['sentences'][0]['sentimentDistribution'])\n",
    "        return np.dot(result['sentences'][0]['sentimentDistribution'], [-2, -1, 0, 1, 2])\n",
    "    elif sentiment_package == 'vader':\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        return analyzer.polarity_scores(clause)['compound']\n",
    "    else:\n",
    "        raise Exception('incorrect sentiment package')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform End-to-End Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = pd.read_csv(\"bus_same_stars_and_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids_similar_stars = bus.business_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RULE:  rule_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22232c274784608be2a009a8c24c5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on restaurant  HhVmDybpU7L50Kb5A0jXTg ...\n",
      "Number of Reviews left after subset length:  1600\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0272579e33ca492fb3faa844d8f66ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49cf1450ab34cc9bb62b57a12dce65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0        fries       3.464529         0.410080\n",
      "1       burger       3.547432         0.432724\n",
      "2    appetizer       3.367589         0.359845\n",
      "3        bacon       3.631478         0.381864\n",
      "4        place       3.325500         0.362662\n",
      "5      service       3.419381         0.292946\n",
      "6         food       3.323452         0.347096\n",
      "7       prices       3.549383         0.196393\n",
      "8        table       2.919732         0.177036\n",
      "9         menu       3.347826         0.327996\n",
      "10       staff       3.508065         0.461639\n",
      "11      cheese       3.564815         0.418166\n",
      "12         bit       3.387805         0.443319\n",
      "13     special       3.163934         0.217323\n",
      "14        meat       2.943231         0.185065\n",
      "15       sauce       3.374723         0.320464\n",
      "16        meal       3.326829         0.387278\n",
      "17        beer       3.432292         0.391274\n",
      "18       lunch       3.620408         0.442098\n",
      "19   breakfast       3.484962         0.372148\n",
      "20      dinner       3.458537         0.419092\n",
      "21  atmosphere       4.126582         0.534596\n",
      "22       taste       2.909639         0.285475\n",
      "23        side       3.357259         0.344811\n",
      "24        pork       3.531532         0.352038\n",
      "25    sandwich       3.502232         0.390017\n",
      "26       price       3.142105         0.278518\n",
      "27      turkey       3.692771         0.385553\n",
      "28       plate       3.040179         0.302656\n",
      "29       salad       3.074627         0.321697\n",
      "30     chicken       3.301818         0.304008\n",
      "31     brisket       3.423077         0.349772\n",
      "32       chili       3.414286         0.379725\n",
      "33       sweet       3.477833         0.653512\n",
      "34     portion       3.786517         0.443381\n",
      "35       steak       3.196581         0.366001\n",
      "36     truffle       3.642857         0.381680\n",
      "Spearman Correlation Score:  0.6972498814604077\n",
      "Running on restaurant  FvVSy2r7_zDEhZWqLgjXNQ ...\n",
      "Number of Reviews left after subset length:  546\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882609a08c84419daedbfcc3cfa87a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552368f518184d21a3c0cf67ecf0ac1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0       lunch       4.163522         0.518554\n",
      "1       place       3.953668         0.505017\n",
      "2        food       3.737527         0.388400\n",
      "3       staff       3.639640         0.549413\n",
      "4    sandwich       3.850365         0.380000\n",
      "5   breakfast       4.187919         0.475593\n",
      "6      cheese       4.138710         0.504835\n",
      "7       bagel       4.070822         0.514473\n",
      "8        soup       4.144385         0.568755\n",
      "9     service       3.675900         0.316525\n",
      "10      cream       4.150000         0.499954\n",
      "Spearman Correlation Score:  0.22727272727272727\n",
      "Running on restaurant  A5Rkh7UymKm0_Rxm9K2PJw ...\n",
      "Number of Reviews left after subset length:  621\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae91f3183d29437fa2313284eaac7ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=621), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8e5c06f06d4c649e15dd4027076b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=621), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0      service       3.900840         0.415684\n",
      "1         food       3.861080         0.465918\n",
      "2         beer       4.031949         0.497981\n",
      "3        place       3.920000         0.535847\n",
      "4         menu       4.080925         0.456804\n",
      "5        fries       3.879781         0.586589\n",
      "6        salad       3.892405         0.517070\n",
      "7      chicken       3.968051         0.480166\n",
      "8        lunch       3.845528         0.515863\n",
      "9        staff       3.906667         0.599783\n",
      "10  atmosphere       4.266667         0.576988\n",
      "11      cheese       3.991111         0.482442\n",
      "12      prices       4.009615         0.497557\n",
      "13      burger       3.905263         0.577714\n",
      "Spearman Correlation Score:  -0.12087912087912088\n",
      "Running on restaurant  GIfZNMP0oIJCje_Xp0Bgrw ...\n",
      "Number of Reviews left after subset length:  377\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc26b99a543f49cfb4f3e15a5aa89fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=377), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673c5dd63e9045ca97646c3d5f8eb5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=377), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0     service       3.476190         0.377129\n",
      "1        food       3.597920         0.422355\n",
      "2      burger       3.572650         0.326832\n",
      "3       staff       3.848684         0.520158\n",
      "4       place       3.607407         0.417535\n",
      "5  atmosphere       3.955224         0.573896\n",
      "6     chicken       3.903475         0.476272\n",
      "7        menu       3.811966         0.504511\n",
      "8        beer       3.742138         0.441993\n",
      "Spearman Correlation Score:  0.9166666666666666\n",
      "Running on restaurant  BjH8Xepc10i6OhCDQdX6og ...\n",
      "Number of Reviews left after subset length:  416\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204e68d39b2b4775939968d1ec0f43bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=416), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453e3d8e206b40bb8b6b89803378746e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=416), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "rules = ['rule_1', 'rule_2', 'rule_3', 'rule_4', 'rule_5', 'rule_6']\n",
    "\n",
    "rule = 'rule_6'\n",
    "\n",
    "correlation_scores = []\n",
    "\n",
    "print(\"RULE: \", rule)\n",
    "for bus_id in tqdm(business_ids_similar_stars):\n",
    "    print(\"Running on restaurant \", bus_id, \"...\")\n",
    "    subset = bus[bus.business_id == bus_id]\n",
    "    \n",
    "    # only get reviews with enough amount of text\n",
    "    reviews_subset = [review for review in subset.text if len(review) < 400]\n",
    "\n",
    "    print(\"Number of Reviews left after subset length: \", len(reviews_subset))\n",
    "    \n",
    "    # get set of entities for this particular restaurant,\n",
    "    # and count how many reviews each entity have\n",
    "    entities_with_count = defaultdict(int) \n",
    "    review_entities = [] # extract entities for each review\n",
    "    print(\"Extracting entities from each review...\")\n",
    "    for review in tqdm(reviews_subset):\n",
    "        entities = get_entities(nlp, review)\n",
    "\n",
    "        # add this review as a count to an entity\n",
    "        for ent in entities:\n",
    "            entities_with_count[ent.lower()] += 1\n",
    "\n",
    "        review_entities.append(entities)\n",
    "        \n",
    "    # only grab entities that have enough reviews\n",
    "    print(\"Filtering entities to have enough reviews...\")\n",
    "    entities_with_enough_reviews = []\n",
    "    threshold = 30\n",
    "    for key, value in entities_with_count.items():\n",
    "        if value >= threshold:\n",
    "            entities_with_enough_reviews.append(key)\n",
    "            \n",
    "    # TRUE RANKINGS CALCULATION\n",
    "    # for each entity, average ratings\n",
    "    true_rankings = defaultdict(list)\n",
    "\n",
    "    print(\"Calculating Yelp Star Rankings... \")\n",
    "    for entity in entities_with_enough_reviews:\n",
    "        true_rankings['entity'] += [entity]\n",
    "        entity_reviews = subset[subset.text.str.contains(entity, case=False)]\n",
    "        true_rankings['average_stars'] += [np.mean(entity_reviews.stars)]\n",
    "\n",
    "    true_rankings = pd.DataFrame(true_rankings)\n",
    "    \n",
    "    # PREDICTION RANKING CALCULATION\n",
    "    print(\"Calculating Prediction Rankings...\")\n",
    "    # Filter entities of each review to be from the entities_with_enough_review set\n",
    "    entity_filter = set(entities_with_enough_reviews)\n",
    "\n",
    "    filtered_entities = []\n",
    "\n",
    "    for entities in review_entities:\n",
    "        filtered = []\n",
    "        for ent in entities:\n",
    "            ent = ent.lower()\n",
    "            if ent in entity_filter:\n",
    "                filtered.append(ent)\n",
    "        filtered_entities.append(filtered)\n",
    "    \n",
    "#     # run validation for each rule\n",
    "#     for rule in rules:\n",
    "\n",
    "    # perform sentiment analysis for each review with filtered entities above\n",
    "    predicted_scores = defaultdict(list)\n",
    "\n",
    "    print(\"Performing sentiment analysis for each review... \")\n",
    "    for i, review in enumerate(tqdm(reviews_subset)):\n",
    "        entities = filtered_entities[i]\n",
    "\n",
    "    #     print(review)\n",
    "\n",
    "        scores = werk(review, entities, parser = parser, sentiment_package='stanford', rule=rule)\n",
    "\n",
    "        # save results \n",
    "        for entity, score in scores:\n",
    "            predicted_scores[entity] += [score]\n",
    "\n",
    "    # create rankings from scores\n",
    "    predicted_rankings = defaultdict(list)\n",
    "    for entity, scores in predicted_scores.items():\n",
    "        predicted_rankings['entity'] += [entity]\n",
    "        predicted_rankings['predicted_score'] += [np.mean(scores)]\n",
    "\n",
    "    predicted_rankings = pd.DataFrame(predicted_rankings)\n",
    "\n",
    "    #### may not be necessary to do these castings\n",
    "    predicted_rankings['entity'] = predicted_rankings['entity'].astype(str)\n",
    "    true_rankings['entity'] = true_rankings['entity'].astype(str)\n",
    "    ####\n",
    "    \n",
    "    full_rankings = true_rankings.merge(predicted_rankings, how='left').fillna(0)\n",
    "\n",
    "    # spearman correlation metric\n",
    "    print(\"Rankings result: \")\n",
    "    print(full_rankings)\n",
    "    \n",
    "    corr, pvalue = spearmanr(full_rankings.average_stars, full_rankings.predicted_score)\n",
    "    print(\"Spearman Correlation Score: \", corr)\n",
    "    correlation_scores.append(corr)\n",
    "        #     print(werk(review, entities, parser = parser,sentiment_package='vader'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Correlation Score: \", np.mean(correlation_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.512625"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [0.697,\n",
    "0.227,\n",
    "0.917,\n",
    "0.825,\n",
    "0.65,\n",
    "0.273,\n",
    "0.4,\n",
    "0.112]\n",
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
