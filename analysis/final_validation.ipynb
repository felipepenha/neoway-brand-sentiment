{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "df_raw = pd.read_json(\"restaurant_reviews_1900k.json\", lines=True)\n",
    "\n",
    "# df = pd.read_csv(\"spacy_train_clean.csv\")\n",
    "# df['entities_clean'] = df['entities_clean'].apply(lambda x: ast.literal_eval(x))\n",
    "# df['entities'] = df.apply(lambda x: [x['text'][i[0]:i[1]] for i in x['entities_clean']],axis=1)\n",
    "\n",
    "# only get restaurants with many reviews\n",
    "many_reviews = df_raw[['business_id','review_id']].groupby(\"business_id\")['review_id'].nunique()\n",
    "many_reviews = many_reviews[many_reviews > 1000].index\n",
    "df = df_raw[df_raw.business_id.isin(set(many_reviews))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses in subset:  142\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of businesses in subset: \", len(df.business_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_stars = df[['business_id', 'stars']].groupby('business_id').mean()\n",
    "business_with_same_stars = business_stars[\n",
    "    (business_stars.stars > 3.5) \n",
    "    & (business_stars.stars < 4.5)].index\n",
    "print(business_with_same_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset reviews\n",
    "bus = df[df.business_id == '-6tvduBzjLI1ISfs3F_qTg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We ended up here after the place next door had an hour wait. They sold us on their $5 drinks but ended up staying for lunch. I got the chicken burrito which looked unassuming but was full of flavor and huge. My wife got the kale salad and it was awesome. We will definitely be back !'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus.text.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [\n",
    "    'salad',\n",
    "    'atmosphere', \n",
    "    'burrito',\n",
    "    'food',\n",
    "    'taco',\n",
    "    'chicken burrito',\n",
    "    'chicken taco',\n",
    "    'carnitas',\n",
    "    'pork adobada',\n",
    "    'carne asada',\n",
    "    'fish taco',\n",
    "    'shrimp taco',\n",
    "    'chips',\n",
    "    'salsa',\n",
    "    'beer',\n",
    "    'tequila',\n",
    "    'margarita',\n",
    "    'mojito'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratings:  3.8768844221105527\n"
     ]
    }
   ],
   "source": [
    "# show average rating for that restaurant\n",
    "print(\"Average Ratings: \", np.mean(bus.stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT FULL NLP process here, for each review, run NLP to create\n",
    "# set of entities and NLP scores to each review\n",
    "\n",
    "# get restaurants with enough entities that have reviews (NEED ER MODEL)\n",
    "\n",
    "# for that restaurant, get set of entities which have enough reviews\n",
    "# (usually with NER, but right now hard code entities, assume NER works well)\n",
    "\n",
    "# manual entity num check \n",
    "# for ent in entities:\n",
    "#     print(\"===================================\\n\")\n",
    "#     sub = bus[bus.text.str.contains(ent, case=False)]\n",
    "#     print(\"Entity: \", ent)\n",
    "#     print(\"Score: \", np.mean(sub.stars))\n",
    "#     print(\"Number of Reviews: \", len(sub))\n",
    "#     print(\"\\n\")\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "rankings = defaultdict(list)\n",
    "\n",
    "# grab all reviews, average ratings \n",
    "for ent in entities:\n",
    "    rankings['entity'] += [ent]\n",
    "    entity_reviews = bus[bus.text.str.contains(ent, case=False)]\n",
    "    rankings['average_stars'] += [np.mean(entity_reviews.stars)]\n",
    "    # insert NLP process here\n",
    "    rankings['predicted'] += [random.uniform(0,5)]\n",
    "# for each entity, calculate avg true rating / average sentiment score (optimization: run before hand)\n",
    "rankings = pd.DataFrame(rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salad</td>\n",
       "      <td>3.969072</td>\n",
       "      <td>4.694935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atmosphere</td>\n",
       "      <td>4.022124</td>\n",
       "      <td>3.188274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>burrito</td>\n",
       "      <td>3.813793</td>\n",
       "      <td>1.071066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food</td>\n",
       "      <td>3.675159</td>\n",
       "      <td>4.760916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taco</td>\n",
       "      <td>3.926329</td>\n",
       "      <td>4.733622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chicken burrito</td>\n",
       "      <td>3.695652</td>\n",
       "      <td>1.662370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chicken taco</td>\n",
       "      <td>3.863636</td>\n",
       "      <td>1.428835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>carnitas</td>\n",
       "      <td>4.135593</td>\n",
       "      <td>3.772582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pork adobada</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.369075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>carne asada</td>\n",
       "      <td>3.826590</td>\n",
       "      <td>3.080352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fish taco</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>2.832862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shrimp taco</td>\n",
       "      <td>3.735294</td>\n",
       "      <td>2.583844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chips</td>\n",
       "      <td>3.558491</td>\n",
       "      <td>3.449337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>salsa</td>\n",
       "      <td>3.646497</td>\n",
       "      <td>3.021830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>beer</td>\n",
       "      <td>4.195402</td>\n",
       "      <td>0.734696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tequila</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.771670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>margarita</td>\n",
       "      <td>4.070755</td>\n",
       "      <td>4.639245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mojito</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>2.772105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             entity  average_stars  predicted\n",
       "0             salad       3.969072   4.694935\n",
       "1        atmosphere       4.022124   3.188274\n",
       "2           burrito       3.813793   1.071066\n",
       "3              food       3.675159   4.760916\n",
       "4              taco       3.926329   4.733622\n",
       "5   chicken burrito       3.695652   1.662370\n",
       "6      chicken taco       3.863636   1.428835\n",
       "7          carnitas       4.135593   3.772582\n",
       "8      pork adobada       4.000000   2.369075\n",
       "9       carne asada       3.826590   3.080352\n",
       "10        fish taco       3.888889   2.832862\n",
       "11      shrimp taco       3.735294   2.583844\n",
       "12            chips       3.558491   3.449337\n",
       "13            salsa       3.646497   3.021830\n",
       "14             beer       4.195402   0.734696\n",
       "15          tequila       4.250000   1.771670\n",
       "16        margarita       4.070755   4.639245\n",
       "17           mojito       4.450000   2.772105"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# rankings.predicted = rankings.average_stars\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  -0.11042311661506708\n"
     ]
    }
   ],
   "source": [
    "# spearman correlation metric\n",
    "corr, pvalue = spearmanr(rankings.average_stars, rankings.predicted)\n",
    "print(\"Spearman Correlation: \", corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
