{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example string to do mini tests on\n",
    "example = \"I just EASILY had the BEST lunch I've ever eaten!  It was THAT good!\\n\\nThe chicken tortilla soup was out of this world...light and delicate...fresh and HOT!!!\\nI had two fish tacos with no tortilla.  One was a regular fish taco and the other was a beer battered fish taco.l\\n\\nThe fire roasted salsa was EASILY the best salsa I have ever had, too!\\n\\nThis place is a serious gem!  I could go there every single day!\\n\\nThanks guys!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Benepar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package benepar_en2 to\n",
      "[nltk_data]     /Users/TimGimi/nltk_data...\n",
      "[nltk_data]   Package benepar_en2 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import benepar\n",
    "benepar.download(\"benepar_en2\")\n",
    "parser = benepar.Parser(\"benepar_en2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Entity Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "model_dir = \"./models\"\n",
    "nlp = spacy.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(nlp_model, text):\n",
    "    \"\"\"\n",
    "    Input nlp_model and text, retrieve a list of unique entities from the text.\n",
    "    \"\"\"\n",
    "    doc = nlp_model(text)\n",
    "    entities = set()\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PRODUCT\":\n",
    "            entities.add(ent.text)\n",
    "    return list(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beer',\n",
       " 'fish',\n",
       " 'gem',\n",
       " 'chicken',\n",
       " 'salsa',\n",
       " 'tortilla',\n",
       " 'place',\n",
       " 'taco',\n",
       " 'lunch',\n",
       " 'soup']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entity_list = get_entities(nlp, example)\n",
    "example_entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick fix\n",
    "#example_entity_list = ['chicken tortilla soup', 'fish tacos', 'tortilla', 'beer battered fish taco', 'fire roasted salasa', 'place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I just EASILY had the BEST lunch I've ever eaten!  It was THAT good!\\n\\nThe chicken tortilla soup was out of this world...light and delicate...fresh and HOT!!!\\nI had two fish tacos with no tortilla.  One was a regular fish taco and the other was a beer battered fish taco.l\\n\\nThe fire roasted salsa was EASILY the best salsa I have ever had, too!\\n\\nThis place is a serious gem!  I could go there every single day!\\n\\nThanks guys!!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "def remove_nestings(lst): \n",
    "    output = []\n",
    "    \n",
    "    def remove_nestings_recursive(l):\n",
    "        for i in l: \n",
    "            if type(i) == list: \n",
    "                remove_nestings_recursive(i) \n",
    "            else: \n",
    "                output.append(i)\n",
    "    \n",
    "    remove_nestings_recursive(lst)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def continue_splitting(review,list_of_dividers):\n",
    "        \n",
    "    temp = list_of_dividers.copy()\n",
    "    l = [review]\n",
    "    while len(temp) > 0:\n",
    "        divider = temp.pop(0)\n",
    "        l_new = []\n",
    "        for i in l:\n",
    "            l_new += i.split(divider)\n",
    "        l = l_new\n",
    "    return l\n",
    "\n",
    "def join_clause(review, list_of_split_clauses, list_of_dividers):\n",
    "    output = []\n",
    "    loc_of_split_clauses = []\n",
    "    for clause in list_of_split_clauses:\n",
    "        loc_of_split_clauses.append(review.find(clause))\n",
    "    for divider in list_of_dividers:\n",
    "        print(divider)\n",
    "        loc_div = review.find(divider)\n",
    "        print(loc_div)\n",
    "        for i in range(len(loc_of_split_clauses)):\n",
    "            if loc_div > loc_of_split_clauses[i]:\n",
    "                print(loc_div,loc_of_split_clauses[i])\n",
    "                \n",
    "def join_partitions(long_review,entity_with_review):\n",
    "    loclist = []\n",
    "    for (_, clause) in entity_with_review:\n",
    "        loclist.append((long_review.find(clause),long_review.find(clause)+len(clause)))\n",
    "    starts = {i for (i,j) in loclist}\n",
    "    ends = {j for (i,j) in loclist}\n",
    "    starts.add(len(long_review))\n",
    "    newends = {}\n",
    "    for i in ends:\n",
    "        newends[i] = min([x for x in starts if x >= i])\n",
    "    for i in newends:\n",
    "        pass\n",
    "    new_entity_with_review = []\n",
    "    for i in range(len(loclist)):\n",
    "        tup = loclist[i]\n",
    "        entity = entity_with_review[i][0]\n",
    "        st = tup[0]\n",
    "        en = newends[tup[1]]\n",
    "        new_entity_with_review.append((entity,long_review[st:en]))\n",
    "    return new_entity_with_review\n",
    "\n",
    "def split_long_string(review):\n",
    "    num = len(review)\n",
    "    split_list = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    while num != end:\n",
    "        if num - end < 1000:\n",
    "            end = num\n",
    "            split_list.append(review[start:end])\n",
    "        else:\n",
    "            end = review[start:(start+1000)].rfind('.')\n",
    "            if end == -1:\n",
    "                end = review[start:(start+1000)].rfind(' ') #if no '.', space will do\n",
    "                if end == -1:\n",
    "                    end = min(start + 1000,num)\n",
    "            split_list.append(review[start:end])\n",
    "            start = end\n",
    "    print(start,end)\n",
    "    return(split_list)\n",
    "\n",
    "def split_review_naive(review,entities):\n",
    "    clauses = re.split('[.?!]',review)\n",
    "    lenlist = [len(x) for x in clauses]\n",
    "    clauses = [x for _, x in sorted(zip(lenlist,clauses),reverse=False)]\n",
    "    entity_with_clause = []\n",
    "    for entity in entities:\n",
    "        for clause in clauses:\n",
    "            if entity in clause:\n",
    "                entity_with_clause.append((entity,clause))\n",
    "                break\n",
    "    return(join_partitions(review,entity_with_clause))\n",
    "\n",
    "def min_tree(review, entities, parser, output = 'minimum'):\n",
    "    \n",
    "    #review is string, entities is list of strings, parser is parser object\n",
    "    # TODO: How well are each review punctuatd and so forth EDA\n",
    "    if output == 'partition':\n",
    "        full_review = ''\n",
    "        \n",
    "    treelist = []\n",
    "    lenlist = []\n",
    "    temp = review.split('\\n')\n",
    "    \n",
    "    if output == 'no_parse':\n",
    "        return(split_review_naive(review,entities))\n",
    "    \n",
    "    if len(review) > 1000:\n",
    "        split_reviews = split_long_string(review)\n",
    "    else:\n",
    "        split_reviews = [i for i in temp if len(i) > 1 and len(i) <= 1000 ]\n",
    "    \n",
    "    for rev in split_reviews:\n",
    "        if rev and rev.strip():\n",
    "            u = parser.parse(rev) # tree \n",
    "\n",
    "            if type(u) == str:\n",
    "                u = nltk.Tree.fromstring(u)\n",
    "\n",
    "            for s in u.subtrees(): # subtrees \n",
    "                if s.label() == 'S': # if sentence\n",
    "                    treelist += [s]\n",
    "                    lenlist += [len(s.leaves())] # how long clause\n",
    "                        \n",
    "            if output == 'partition':\n",
    "                full_review += ' '.join(u.leaves()) + ' '\n",
    "\n",
    "    treelist = [x for _, x in sorted(zip(lenlist,treelist),reverse=False)] # sort by lenlisit\n",
    "    clauses = [' '.join(tree.leaves()) for tree in treelist]\n",
    "    \n",
    "    #If there is no sentences detected, then the full review is the only clause.\n",
    "    if not clauses:\n",
    "        if output == 'partition':\n",
    "            clauses.append(full_review)\n",
    "        else:\n",
    "            clauses.append(review)\n",
    "    entity_with_clause = []\n",
    "    \n",
    "    if output == 'all':\n",
    "        for entity in entities:\n",
    "            clauselist = []\n",
    "            for clause in clauses:\n",
    "                if entity in clause:\n",
    "                    clauselist.append(clause)\n",
    "            entity_with_clause.append((entity,clauselist))\n",
    "    \n",
    "    #TODO: create rules and test them\n",
    "    elif output == 'minimum':\n",
    "        for entity in entities:\n",
    "            for clause in clauses:\n",
    "                if entity in clause:\n",
    "                    entity_with_clause.append((entity,clause))\n",
    "                    break\n",
    "                    \n",
    "    elif output == 'partition':\n",
    "        #first find minimal clause\n",
    "        for entity in entities:\n",
    "            for clause in clauses:\n",
    "                if entity in clause:\n",
    "                    entity_with_clause.append((entity,clause))\n",
    "                    break\n",
    "        #get location of minimal clause in review\n",
    "        \n",
    "        entity_with_clause = join_partitions(full_review,entity_with_clause)\n",
    "    \n",
    "    return entity_with_clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANFORD NLP\n",
    "import numpy as np\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "def stanford_sentiment_start():\n",
    "    nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "    return nlp\n",
    "\n",
    "def stanford_sentiment(entity_with_clause):\n",
    "    nlp = stanford_sentiment_start()\n",
    "    entity_with_sentiment = []\n",
    "    for entity, clause in entity_with_clause:\n",
    "        result = nlp.annotate(clause,\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json'\n",
    "                   })\n",
    "        sentiment = np.dot(result['sentences'][0]['sentimentDistribution'], [-2, -1, 0, 1, 2])\n",
    "        entity_with_sentiment.append((entity, sentiment))\n",
    "    return entity_with_sentiment\n",
    "\n",
    "#VADER\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def vader_sentiment(entity_with_clause):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    entity_with_sentiment = []\n",
    "    for entity, clause in entity_with_clause:\n",
    "        sentiment = analyzer.polarity_scores(clause)['compound']\n",
    "        entity_with_sentiment.append((entity,sentiment))\n",
    "    return(entity_with_sentiment)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Werk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def werk(review, entities, parser = [], sentiment_package = 'vader', parse_package = 'benepar', rule = 'rule_1'):\n",
    "    \n",
    "    #print(\"\\nLoading Parser\")\n",
    "    \n",
    "    #first is the parser\n",
    "    if not parser and parse_package == 'benepar':\n",
    "        parser = benepar.Parser(\"benepar_en2\")\n",
    "    elif not parser and parse_package == 'stanford':\n",
    "        #parser = StanfordNLP('http://localhost')\n",
    "        raise Exception('incorrect parse package')\n",
    "    elif parser:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('incorrect parse package')\n",
    "    \n",
    "    #print(\"Parser =\", parse_package)\n",
    "\n",
    "        \n",
    "    #second is the rule\n",
    "    \n",
    "    #print(\"\\nLoading Rule\")\n",
    "    \n",
    "    if rule == 'rule_1':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'minimum')\n",
    "        \n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        \n",
    "        #print(\"\\nSentiment Generated\")\n",
    "\n",
    "        \n",
    "    elif rule == 'rule_2':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'all')\n",
    "        \n",
    "        #print(\"\\nTree Generated\")\n",
    "        entity_with_sentiment = []\n",
    "        sentiment = 0\n",
    "        for ent, revlist in entity_with_review:\n",
    "            for clause in revlist:\n",
    "                sentiment = sentiment_analysis_indiv(clause,sentiment_package)\n",
    "                if sentiment_package == 'benepar' and abs(sentiment) != 0:\n",
    "                    break\n",
    "                elif sentiment_package == 'stanford' and abs(sentiment) > 0.5:\n",
    "                    break\n",
    "                    #if sentiment is not neutral, stop. If sentiment is neutral, keep going up tree.\n",
    "            entity_with_sentiment.append((ent,sentiment))\n",
    "        #print(\"\\nSentiment Generated\")        \n",
    "        \n",
    "    elif rule == 'rule_3':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'all')\n",
    "        \n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = []\n",
    "        for ent, revlist in entity_with_review:\n",
    "            sentiment_list = []\n",
    "            for clause in revlist:\n",
    "                sentiment = sentiment_analysis_indiv(clause,sentiment_package)\n",
    "                sentiment_list.append(sentiment)\n",
    "            entity_with_sentiment.append((ent,np.mean(sentiment_list)))\n",
    "            \n",
    "        #print(\"\\nSentiment Generated\") \n",
    "        \n",
    "    elif rule == 'rule_4':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'partition')\n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        \n",
    "        #print(\"\\nSentiment Generated\")\n",
    "        \n",
    "    elif rule == 'rule_5':\n",
    "        \n",
    "        #print(\"Rule =\",rule)\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'minimum')\n",
    "        entity_with_review_p = min_tree(review, entities, parser, output = 'partition')\n",
    "        #print(\"\\nTree Generated\")\n",
    "        \n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        for i in range(len(entity_with_sentiment)):\n",
    "            sent = entity_with_sentiment[i][1]\n",
    "            if sentiment_package == 'vader' and sent != 0:\n",
    "                entity_with_sentiment[i] = (entity_with_sentiment[i][0],sentiment_analysis_indiv(entity_with_review_p[i][1],sentiment_package))\n",
    "            elif sentiment_package == 'stanford' and abs(sent) > 0.5:\n",
    "                entity_with_sentiment[i] = (entity_with_sentiment[i][0],sentiment_analysis_indiv(entity_with_review_p[i][1],sentiment_package))\n",
    "    \n",
    "    elif rule == 'rule_6':\n",
    "        \n",
    "        entity_with_review = min_tree(review, entities, parser, output = 'no_parse')\n",
    "        entity_with_sentiment = sentiment_analysis(entity_with_review, sentiment_package)\n",
    "        \n",
    "        #print(\"\\nSentiment Generated\")\n",
    "    \n",
    "    else:\n",
    "        raise Exception('incorrect rule')\n",
    "    \n",
    "    return(entity_with_sentiment)\n",
    "    \n",
    "def sentiment_analysis(entity_with_review, sentiment_package = 'stanford'):\n",
    "    #takes in list of tuples\n",
    "    if sentiment_package == 'stanford':\n",
    "        return stanford_sentiment(entity_with_review)\n",
    "    elif sentiment_package == 'vader':\n",
    "        return vader_sentiment(entity_with_review)\n",
    "    else:\n",
    "        raise Exception('incorrect sentiment package')\n",
    "\n",
    "def sentiment_analysis_indiv(clause,sentiment_package = 'stanford'):\n",
    "    #takes in a single review\n",
    "    if sentiment_package == 'stanford':\n",
    "        nlp = stanford_sentiment_start()\n",
    "        result = nlp.annotate(clause,\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json'\n",
    "                   })\n",
    "        print(result['sentences'][0]['sentimentDistribution'])\n",
    "        return np.dot(result['sentences'][0]['sentimentDistribution'], [-2, -1, 0, 1, 2])\n",
    "    elif sentiment_package == 'vader':\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        return analyzer.polarity_scores(clause)['compound']\n",
    "    else:\n",
    "        raise Exception('incorrect sentiment package')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform End-to-End Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses in subset:  142\n",
      "Number of businesses with 3.5-4.5 stars:  57\n"
     ]
    }
   ],
   "source": [
    "# GET ALL RESTAURANTS \n",
    "\n",
    "# import data\n",
    "df_raw = pd.read_json(\"restaurant_reviews_1900k.json\", lines=True)\n",
    "\n",
    "# only get restaurants with many reviews\n",
    "many_reviews = df_raw[['business_id','review_id']].groupby(\"business_id\")['review_id'].nunique()\n",
    "many_reviews = many_reviews[many_reviews > 1000].index # more than 100 reviews\n",
    "df = df_raw[df_raw.business_id.isin(set(many_reviews))]\n",
    "print(\"Number of businesses in subset: \", len(df.business_id.unique()))\n",
    "\n",
    "# only grab restaurants with 3-4 stars\n",
    "business_stars = df[['business_id', 'stars']].groupby('business_id').mean()\n",
    "business_ids_similar_stars= business_stars[\n",
    "    (business_stars.stars >= 3.0) \n",
    "    & (business_stars.stars <= 4.0)].index\n",
    "\n",
    "print(\"Number of businesses with 3.5-4.5 stars: \", len(business_ids_similar_stars.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = df[df.business_id.isin(set(business_ids_similar_stars[:50]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus.to_csv(\"restaurants_with_enough_stars_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids_similar_stars = bus.business_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RULE:  rule_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37cbb0212094bceb6d66edfaf245968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on restaurant  d_L-rfS1vT3JMzgCUGtiow ...\n",
      "Number of Reviews left after subset length:  679\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2a3d0511ea4b2ea9a9267fbc8a85b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=679), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3162ac95a0472eb0f9e03a0dc361fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=679), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0         fish       3.533333         0.467778\n",
      "1        staff       4.046512         0.633719\n",
      "2         food       3.826979         0.562120\n",
      "3      service       3.904552         0.566233\n",
      "4      chicken       3.864151         0.692516\n",
      "5         corn       3.955285         0.741853\n",
      "6   atmosphere       4.108696         0.647784\n",
      "7         menu       4.064815         0.680333\n",
      "8    margarita       3.813559         0.654366\n",
      "9         meal       3.812081         0.617319\n",
      "10       steak       4.108844         0.653063\n",
      "11   guacamole       3.842105         0.694223\n",
      "12       place       3.782772         0.599642\n",
      "13       lunch       4.032864         0.622830\n",
      "14       salsa       3.706849         0.695825\n",
      "15      dinner       3.873874         0.687476\n",
      "16     special       3.912698         0.727147\n",
      "Spearman Correlation Score:  0.22058823529411767\n",
      "Running on restaurant  N0apJkxIem2E8irTBRKnHw ...\n",
      "Number of Reviews left after subset length:  711\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ba2dce89ec44cfb3b0126afafa6428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=711), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c458bc55a84df9b0f1563b6dd6f17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=711), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "         entity  average_stars  predicted_score\n",
      "0       service       3.959103         0.578228\n",
      "1          food       3.888521         0.552700\n",
      "2         place       3.937050         0.634821\n",
      "3          menu       4.026415         0.679868\n",
      "4        dinner       4.055351         0.702276\n",
      "5          crab       3.886957         0.516650\n",
      "6         price       3.785530         0.603861\n",
      "7         pizza       3.904573         0.580403\n",
      "8         staff       4.228571         0.693377\n",
      "9         pasta       3.835979         0.592154\n",
      "10          bit       3.762411         0.647967\n",
      "11        lunch       3.994709         0.678735\n",
      "12       burger       3.974747         0.645167\n",
      "13       potato       4.054902         0.655875\n",
      "14  blue cheese       4.013333         0.663441\n",
      "15   atmosphere       4.061856         0.478476\n",
      "16       prices       3.939850         0.584797\n",
      "17         meal       3.955556         0.637195\n",
      "18      chicken       3.959375         0.628001\n",
      "19        bread       3.808511         0.531867\n",
      "20        steak       4.014085         0.611425\n",
      "21       cheese       4.008451         0.685135\n",
      "22        salad       3.980769         0.601305\n",
      "Spearman Correlation Score:  0.5177865612648221\n",
      "Running on restaurant  IMLrj2klosTFvPRLv56cng ...\n",
      "Number of Reviews left after subset length:  679\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca530d36164f4d85bc68050be0679078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=679), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12c97f74021482ea8c3cc77426c9b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=679), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0      service       3.901774         0.601628\n",
      "1       cheese       3.900000         0.762764\n",
      "2        place       3.953243         0.743835\n",
      "3        table       3.638191         0.707831\n",
      "4        bread       3.953416         0.661675\n",
      "5         food       3.883984         0.622737\n",
      "6         menu       3.869658         0.618816\n",
      "7      dessert       3.984375         0.652098\n",
      "8     sandwich       3.978541         0.645788\n",
      "9        lunch       3.954064         0.685100\n",
      "10  atmosphere       4.210084         0.626412\n",
      "11     chicken       3.908072         0.683115\n",
      "12       pizza       3.857143         0.734281\n",
      "13       staff       4.008584         0.747724\n",
      "14        meal       3.700389         0.683798\n",
      "15       salad       3.972067         0.753769\n",
      "16      dinner       3.978056         0.771343\n",
      "Spearman Correlation Score:  0.06862745098039216\n",
      "Running on restaurant  ujHiaprwCQ5ewziu0Vi9rw ...\n",
      "Number of Reviews left after subset length:  1698\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96fc960a5874073befd2f1de2f99a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1698), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3367d5cce974968b6df7a8e8f410b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1698), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0        meat       3.432749         0.372643\n",
      "1     dessert       3.586803         0.455950\n",
      "2       steak       3.537764         0.515530\n",
      "3      dinner       3.526952         0.393924\n",
      "4       sushi       3.466799         0.468228\n",
      "5        crab       3.396911         0.367581\n",
      "6      buffet       3.399582         0.417000\n",
      "7       price       3.330591         0.419884\n",
      "8   breakfast       3.678261         0.534913\n",
      "9        food       3.294837         0.384290\n",
      "10      place       3.265097         0.357977\n",
      "11      taste       2.984314         0.345219\n",
      "12    service       3.393973         0.427818\n",
      "13        rib       3.322917         0.461583\n",
      "14     coffee       3.323864         0.489191\n",
      "15       beef       3.603960         0.387062\n",
      "16    seafood       3.586146         0.468716\n",
      "17       lamb       3.755102         0.444968\n",
      "18       fish       3.304348         0.360169\n",
      "19        bit       3.510909         0.527990\n",
      "20      staff       3.147766         0.459082\n",
      "21  champagne       3.788177         0.576768\n",
      "22      lunch       3.677989         0.432466\n",
      "23       meal       3.264059         0.356766\n",
      "24      salad       3.585455         0.371193\n",
      "25      pizza       3.500000         0.292754\n",
      "26     salmon       3.537530         0.475864\n",
      "27    special       3.231263         0.282950\n",
      "28      pasta       3.484487         0.451974\n",
      "Spearman Correlation Score:  0.5211822660098521\n",
      "Running on restaurant  OVTZNSkSfbl3gVB9XQIJfw ...\n",
      "Number of Reviews left after subset length:  561\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03041e3cb25044daa9ceb0ae645ece11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=561), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4983bb8ac0e4d9493584139fb451f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=561), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0      buffet       3.224237         0.412168\n",
      "1         rib       3.005277         0.447278\n",
      "2       sushi       3.274368         0.378036\n",
      "3        crab       3.254795         0.400640\n",
      "4     service       3.179104         0.495357\n",
      "5        food       3.134766         0.427099\n",
      "6       place       3.154519         0.460699\n",
      "7       price       3.275229         0.494116\n",
      "8       lunch       3.331633         0.439430\n",
      "9   breakfast       3.357759         0.477995\n",
      "10     dinner       3.231343         0.480467\n",
      "11       wine       3.415301         0.534457\n",
      "12       beer       3.394886         0.470424\n",
      "13    dessert       3.211137         0.449806\n",
      "14      staff       3.299213         0.530106\n",
      "Spearman Correlation Score:  0.3571428571428571\n",
      "Running on restaurant  HhVmDybpU7L50Kb5A0jXTg ...\n",
      "Number of Reviews left after subset length:  1600\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cf5d590ae34bbcbae2f1806d366a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4eeda864034a2fb50b1118b7ce0bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0    appetizer       3.367589         0.509477\n",
      "1        bacon       3.631478         0.536297\n",
      "2        fries       3.464529         0.590646\n",
      "3       burger       3.547432         0.613730\n",
      "4        place       3.325500         0.495848\n",
      "5      service       3.419381         0.447595\n",
      "6       prices       3.549383         0.504995\n",
      "7         food       3.323452         0.477334\n",
      "8        table       2.919732         0.286647\n",
      "9         menu       3.347826         0.460614\n",
      "10      cheese       3.564815         0.587585\n",
      "11       staff       3.508065         0.615649\n",
      "12     special       3.163934         0.379407\n",
      "13         bit       3.387805         0.689771\n",
      "14        meat       2.943231         0.332509\n",
      "15        meal       3.326829         0.495678\n",
      "16        beer       3.432292         0.570860\n",
      "17       sauce       3.374723         0.408923\n",
      "18   breakfast       3.484962         0.533057\n",
      "19      dinner       3.458537         0.578832\n",
      "20       lunch       3.620408         0.599140\n",
      "21  atmosphere       4.126582         0.588280\n",
      "22       taste       2.909639         0.424296\n",
      "23        side       3.357259         0.502526\n",
      "24        pork       3.531532         0.495647\n",
      "25    sandwich       3.502232         0.563264\n",
      "26       price       3.142105         0.479328\n",
      "27       plate       3.040179         0.515053\n",
      "28      turkey       3.692771         0.502603\n",
      "29       salad       3.074627         0.527626\n",
      "30     chicken       3.301818         0.446784\n",
      "31     brisket       3.423077         0.531487\n",
      "32       chili       3.414286         0.449716\n",
      "33       sweet       3.477833         0.774826\n",
      "34     portion       3.786517         0.538168\n",
      "35       steak       3.196581         0.547645\n",
      "36     truffle       3.642857         0.629373\n",
      "Spearman Correlation Score:  0.6377430061640588\n",
      "Running on restaurant  XXW_OFaYQkkGOGniujZFHg ...\n",
      "Number of Reviews left after subset length:  1709\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bf70de67f2466ba80e96509a0bc671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1709), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad738c28bf0148eaba96be7b45f81fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1709), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0        place       4.010620         0.598513\n",
      "1      service       3.852230         0.570630\n",
      "2         food       3.917914         0.561857\n",
      "3   atmosphere       4.151436         0.628483\n",
      "4    breakfast       4.143617         0.602430\n",
      "5          bit       3.694704         0.593442\n",
      "6        split       4.145985         0.607717\n",
      "7         meal       3.967667         0.629794\n",
      "8        price       3.952672         0.657327\n",
      "9       prices       4.032143         0.528145\n",
      "10        eggs       3.970721         0.676019\n",
      "11       steak       3.882143         0.648489\n",
      "12        menu       4.066667         0.551851\n",
      "13     portion       4.178002         0.617227\n",
      "14     chicken       3.869048         0.635675\n",
      "15       staff       4.138554         0.688039\n",
      "16       taste       3.431159         0.653367\n",
      "17    cocktail       4.091988         0.546540\n",
      "18      omelet       4.050398         0.584161\n",
      "19      coffee       3.776190         0.512795\n",
      "20       lunch       4.245614         0.644960\n",
      "21      dinner       3.958904         0.603896\n",
      "22      burger       3.732143         0.689233\n",
      "23        hash       3.860000         0.597643\n",
      "24       fries       3.857143         0.649326\n",
      "25       table       3.768775         0.539953\n",
      "26        side       3.985915         0.513450\n",
      "27    omelette       4.052632         0.653574\n",
      "28       plate       3.955645         0.659997\n",
      "Spearman Correlation Score:  0.010837438423645318\n",
      "Running on restaurant  Wxxvi3LZbHNIDwJ-ZimtnA ...\n",
      "Number of Reviews left after subset length:  1195\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1308c90cd04c55a840c4bff39284a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1195), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce619956f8734dc2890160a54ca05b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1195), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "    entity  average_stars  predicted_score\n",
      "0    price       3.900542         0.409660\n",
      "1     food       4.048000         0.612592\n",
      "2    staff       3.993600         0.622479\n",
      "3  service       3.663208         0.403768\n",
      "4    place       3.962097         0.603129\n",
      "5      bit       3.831522         0.442616\n",
      "6  gondola       4.423077         0.624935\n",
      "Spearman Correlation Score:  0.9285714285714288\n",
      "Running on restaurant  thLX_k20SPJ0KyusGTBIHw ...\n",
      "Number of Reviews left after subset length:  615\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632a3433e8424b0f964aa4295f0cf2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=615), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcbb253495a4d14b2af8bd0e71ec3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=615), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0        place       3.977427         0.683997\n",
      "1        staff       4.101010         0.675380\n",
      "2      service       3.701422         0.524863\n",
      "3         food       3.838710         0.602496\n",
      "4       sprout       4.153846         0.756607\n",
      "5   atmosphere       4.253333         0.625854\n",
      "6      chicken       4.094595         0.684817\n",
      "7      coconut       4.314607         0.715271\n",
      "8         taco       4.094270         0.594366\n",
      "9         corn       4.092437         0.694728\n",
      "10        menu       4.036765         0.784167\n",
      "11       steak       4.155963         0.572323\n",
      "12   guacamole       4.164557         0.701639\n",
      "13       lunch       3.927711         0.662542\n",
      "14   margarita       4.179039         0.556529\n",
      "15       salsa       3.891720         0.733379\n",
      "16       green       4.250000         0.649883\n",
      "Spearman Correlation Score:  0.03921568627450981\n",
      "Running on restaurant  uuGL8diLlHfeUeFuod3F-w ...\n",
      "Number of Reviews left after subset length:  923\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f797e7451f7c4d8cb4e3dc7fbdd295b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=923), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead4ac2afdaa43529f15656fdcda3549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=923), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0      service       3.497347         0.405825\n",
      "1        steak       3.584615         0.539988\n",
      "2         food       3.557978         0.494794\n",
      "3         meal       3.574257         0.708223\n",
      "4    breakfast       3.818841         0.620011\n",
      "5         beer       3.692308         0.613058\n",
      "6   atmosphere       4.320000         0.583565\n",
      "7     sandwich       3.682759         0.661073\n",
      "8        staff       3.900000         0.778225\n",
      "9        place       3.569536         0.538981\n",
      "10        menu       3.626113         0.579674\n",
      "11       fries       3.637209         0.688911\n",
      "12      burger       3.587065         0.582888\n",
      "13       bacon       3.675214         0.474486\n",
      "14        eggs       3.338710         0.617955\n",
      "15       lunch       3.650000         0.757042\n",
      "16     lobster       4.033333         0.619139\n",
      "17      cheese       3.625000         0.522139\n",
      "18     chicken       3.752688         0.601963\n",
      "19      dinner       3.874074         0.657550\n",
      "20       salad       3.414062         0.500545\n",
      "Spearman Correlation Score:  0.487012987012987\n",
      "Running on restaurant  FvVSy2r7_zDEhZWqLgjXNQ ...\n",
      "Number of Reviews left after subset length:  546\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933aac758fd146dda87ee13f15b24181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e234385f4255454bb177046f68cc8739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0       lunch       4.163522         0.693967\n",
      "1       place       3.953668         0.590055\n",
      "2        food       3.737527         0.513489\n",
      "3       staff       3.639640         0.673472\n",
      "4   breakfast       4.187919         0.633165\n",
      "5    sandwich       3.850365         0.477500\n",
      "6      cheese       4.138710         0.597128\n",
      "7       bagel       4.070822         0.671041\n",
      "8        soup       4.144385         0.688893\n",
      "9     service       3.675900         0.471231\n",
      "10      cream       4.150000         0.624886\n",
      "Spearman Correlation Score:  0.5090909090909091\n",
      "Running on restaurant  _j2EtQtgLuXGRBfbM5YwZA ...\n",
      "Number of Reviews left after subset length:  522\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e035e01e04d34a9fa0627de3605bef57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=522), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a193b341e5c41eabd4a3883733cd864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=522), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "     entity  average_stars  predicted_score\n",
      "0      beef       3.577215         0.476348\n",
      "1      rice       3.418440         0.464285\n",
      "2      soup       3.571970         0.491694\n",
      "3    noodle       3.522572         0.450246\n",
      "4   service       3.111111         0.293843\n",
      "5     taste       3.010256         0.364928\n",
      "6      pork       3.506024         0.323164\n",
      "7     place       3.385230         0.471569\n",
      "8      food       3.297222         0.357947\n",
      "9     price       3.406915         0.450993\n",
      "10  chicken       3.149425         0.367736\n",
      "11     duck       3.537736         0.407471\n",
      "12   prices       3.415929         0.421200\n",
      "Spearman Correlation Score:  0.6043956043956044\n",
      "Running on restaurant  TCoBE_BkDRrK0bWrh5VueQ ...\n",
      "Number of Reviews left after subset length:  644\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6f18495d254e2797f0d29efcd66f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=644), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0479d3ce94b475f8cad9088648fa522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=644), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0       staff       3.943396         0.527187\n",
      "1        food       3.726048         0.501938\n",
      "2       place       3.892913         0.635896\n",
      "3        taco       3.993541         0.538303\n",
      "4        corn       4.123188         0.610894\n",
      "5  atmosphere       4.296296         0.654280\n",
      "6        beer       4.215686         0.668109\n",
      "7       salsa       3.963696         0.615722\n",
      "8     service       3.450216         0.561966\n",
      "9        meat       3.811321         0.350400\n",
      "Spearman Correlation Score:  0.6606060606060605\n",
      "Running on restaurant  n8Zqqhff-2cxzWt_nwhU2Q ...\n",
      "Number of Reviews left after subset length:  619\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776d1b06d73948c4b9fc89540e9e102a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=619), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c071f9ab5f464158880515b80c5ba0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=619), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "         entity  average_stars  predicted_score\n",
      "0   cauliflower       4.105528         0.780275\n",
      "1       service       3.612245         0.515730\n",
      "2         place       3.649695         0.608642\n",
      "3          menu       3.789174         0.679038\n",
      "4         staff       3.615942         0.639931\n",
      "5    atmosphere       4.036458         0.625811\n",
      "6          beer       3.953368         0.633033\n",
      "7          food       3.659751         0.567364\n",
      "8       chicken       3.938889         0.754408\n",
      "9        burger       3.771144         0.842302\n",
      "10       cheese       3.917582         0.668717\n",
      "11        pizza       3.786207         0.552206\n",
      "12        salad       3.863946         0.837088\n",
      "13      buffalo       4.123188         0.771054\n",
      "Spearman Correlation Score:  0.4769230769230769\n",
      "Running on restaurant  gx2yPrOJSwF1ApJYdGBWIw ...\n",
      "Number of Reviews left after subset length:  786\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919386ad37d3411d92c62d68c7f53300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=786), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d8b369068d4329928f27bf26097777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=786), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0        staff       4.118012         0.715561\n",
      "1        place       4.036709         0.685156\n",
      "2        broth       3.956416         0.664862\n",
      "3          bun       4.161137         0.631682\n",
      "4      service       3.837209         0.543923\n",
      "5         food       3.792722         0.543837\n",
      "6        table       3.663636         0.517956\n",
      "7        taste       3.697095         0.589877\n",
      "8   atmosphere       4.373913         0.707000\n",
      "9      chicken       4.106818         0.618984\n",
      "10       lunch       4.260417         0.677384\n",
      "11        pork       4.193750         0.691686\n",
      "12      garlic       4.168539         0.834522\n",
      "13        soup       3.880952         0.654093\n",
      "14        menu       4.052419         0.689824\n",
      "Spearman Correlation Score:  0.7714285714285712\n",
      "Running on restaurant  YPavuOh2XsnRbLfl0DH2lQ ...\n",
      "Number of Reviews left after subset length:  917\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cb0bbfe30c4026901cedd44ff988bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=917), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e6807edae542e5a289e16d9d1abf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=917), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0        grits       4.315534         0.566869\n",
      "1      chicken       4.035266         0.631664\n",
      "2         food       3.775000         0.494032\n",
      "3      service       3.640625         0.450563\n",
      "4       cheese       4.184211         0.652937\n",
      "5        staff       3.924901         0.579029\n",
      "6        place       3.981037         0.571775\n",
      "7       waffle       4.070255         0.546594\n",
      "8   atmosphere       4.193103         0.670682\n",
      "9      catfish       3.867925         0.514852\n",
      "10       lunch       3.656934         0.707656\n",
      "11        side       3.951168         0.528735\n",
      "12       sweet       4.262500         0.798169\n",
      "13         bit       3.942222         0.647559\n",
      "14   soul food       4.013158         0.645838\n",
      "15        meal       3.666667         0.410463\n",
      "16      greens       4.148936         0.638841\n",
      "17         tea       4.045802         0.766170\n",
      "18        menu       3.975124         0.745159\n",
      "Spearman Correlation Score:  0.4842105263157894\n",
      "Running on restaurant  JyxHvtj-syke7m9rbza7mA ...\n",
      "Number of Reviews left after subset length:  725\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e284102f474849f7bcb78bebde5679f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=725), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02b128cb0664ac29c6a8e766331193a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=725), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rankings result: \n",
      "     entity  average_stars  predicted_score\n",
      "0     sushi       3.883817         0.535358\n",
      "1     place       3.776492         0.539484\n",
      "2      food       3.488473         0.462014\n",
      "3      fish       3.872302         0.533455\n",
      "4      menu       4.107981         0.685692\n",
      "5     lunch       3.839286         0.472768\n",
      "6    dinner       3.949008         0.507178\n",
      "7   dessert       4.235751         0.618517\n",
      "8   service       3.457729         0.374275\n",
      "9      tuna       3.990476         0.627502\n",
      "10     rice       3.760766         0.442118\n",
      "11    table       3.302703         0.407368\n",
      "12    price       3.815331         0.435960\n",
      "13     roll       4.020962         0.629870\n",
      "14    staff       3.634286         0.607153\n",
      "15   salmon       4.097792         0.534047\n",
      "Spearman Correlation Score:  0.7411764705882353\n",
      "Running on restaurant  K7lWdNUhCbcnEvI0NhGewg ...\n",
      "Number of Reviews left after subset length:  2374\n",
      "Extracting entities from each review...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e8e09813244ffebd18d6a9d3e54991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2374), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91039968e54d48bf9062ad1f70784c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2374), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "rules = ['rule_1', 'rule_2', 'rule_3', 'rule_4', 'rule_5', 'rule_6']\n",
    "\n",
    "rule = 'rule_2'\n",
    "\n",
    "correlation_scores = []\n",
    "\n",
    "print(\"RULE: \", rule)\n",
    "for bus_id in tqdm(business_ids_similar_stars):\n",
    "    print(\"Running on restaurant \", bus_id, \"...\")\n",
    "    subset = bus[bus.business_id == bus_id]\n",
    "    \n",
    "    # only get reviews with enough amount of text\n",
    "    reviews_subset = [review for review in subset.text if len(review) < 400]\n",
    "\n",
    "    print(\"Number of Reviews left after subset length: \", len(reviews_subset))\n",
    "    \n",
    "    # get set of entities for this particular restaurant,\n",
    "    # and count how many reviews each entity have\n",
    "    entities_with_count = defaultdict(int) \n",
    "    review_entities = [] # extract entities for each review\n",
    "    print(\"Extracting entities from each review...\")\n",
    "    for review in tqdm(reviews_subset):\n",
    "        entities = get_entities(nlp, review)\n",
    "\n",
    "        # add this review as a count to an entity\n",
    "        for ent in entities:\n",
    "            entities_with_count[ent.lower()] += 1\n",
    "\n",
    "        review_entities.append(entities)\n",
    "        \n",
    "    # only grab entities that have enough reviews\n",
    "    print(\"Filtering entities to have enough reviews...\")\n",
    "    entities_with_enough_reviews = []\n",
    "    threshold = 30\n",
    "    for key, value in entities_with_count.items():\n",
    "        if value >= threshold:\n",
    "            entities_with_enough_reviews.append(key)\n",
    "            \n",
    "    # TRUE RANKINGS CALCULATION\n",
    "    # for each entity, average ratings\n",
    "    true_rankings = defaultdict(list)\n",
    "\n",
    "    print(\"Calculating Yelp Star Rankings... \")\n",
    "    for entity in entities_with_enough_reviews:\n",
    "        true_rankings['entity'] += [entity]\n",
    "        entity_reviews = subset[subset.text.str.contains(entity, case=False)]\n",
    "        true_rankings['average_stars'] += [np.mean(entity_reviews.stars)]\n",
    "\n",
    "    true_rankings = pd.DataFrame(true_rankings)\n",
    "    \n",
    "    # PREDICTION RANKING CALCULATION\n",
    "    print(\"Calculating Prediction Rankings...\")\n",
    "    # Filter entities of each review to be from the entities_with_enough_review set\n",
    "    entity_filter = set(entities_with_enough_reviews)\n",
    "\n",
    "    filtered_entities = []\n",
    "\n",
    "    for entities in review_entities:\n",
    "        filtered = []\n",
    "        for ent in entities:\n",
    "            ent = ent.lower()\n",
    "            if ent in entity_filter:\n",
    "                filtered.append(ent)\n",
    "        filtered_entities.append(filtered)\n",
    "    \n",
    "#     # run validation for each rule\n",
    "#     for rule in rules:\n",
    "\n",
    "    # perform sentiment analysis for each review with filtered entities above\n",
    "    predicted_scores = defaultdict(list)\n",
    "\n",
    "    print(\"Performing sentiment analysis for each review... \")\n",
    "    for i, review in enumerate(tqdm(reviews_subset)):\n",
    "        entities = filtered_entities[i]\n",
    "\n",
    "    #     print(review)\n",
    "\n",
    "        scores = werk(review, entities, parser = parser, sentiment_package='vader', rule=rule)\n",
    "\n",
    "        # save results \n",
    "        for entity, score in scores:\n",
    "            predicted_scores[entity] += [score]\n",
    "\n",
    "    # create rankings from scores\n",
    "    predicted_rankings = defaultdict(list)\n",
    "    for entity, scores in predicted_scores.items():\n",
    "        predicted_rankings['entity'] += [entity]\n",
    "        predicted_rankings['predicted_score'] += [np.mean(scores)]\n",
    "\n",
    "    predicted_rankings = pd.DataFrame(predicted_rankings)\n",
    "\n",
    "    #### may not be necessary to do these castings\n",
    "    predicted_rankings['entity'] = predicted_rankings['entity'].astype(str)\n",
    "    true_rankings['entity'] = true_rankings['entity'].astype(str)\n",
    "    ####\n",
    "    \n",
    "    full_rankings = true_rankings.merge(predicted_rankings, how='left').fillna(0)\n",
    "\n",
    "    # spearman correlation metric\n",
    "    print(\"Rankings result: \")\n",
    "    print(full_rankings)\n",
    "    \n",
    "    corr, pvalue = spearmanr(full_rankings.average_stars, full_rankings.predicted_score)\n",
    "    print(\"Spearman Correlation Score: \", corr)\n",
    "    correlation_scores.append(corr)\n",
    "        #     print(werk(review, entities, parser = parser,sentiment_package='vader'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vegas Fries - Bomb  \\nWings - chewy & overcooked; not very flavorful \\nBacon Mac n Cheese Burger - too much going on that I couldn't even taste the Mac n Cheese\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_subset[1023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taste', -0.4939)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "werk(review, entities, parser = parser, sentiment_package='vader', rule=rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Correlation Score:  0.31726939016412703\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Correlation Score: \", np.mean(correlation_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.684,\n",
    "0.145,\n",
    "0.467,\n",
    "0.392,\n",
    "0.225,\n",
    "-0.203,\n",
    "0.2,\n",
    "0.0198,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24122500000000002"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
